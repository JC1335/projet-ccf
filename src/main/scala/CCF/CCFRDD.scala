package ccf

import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.functions._

object CCFRDD {
  def main(args: Array[String]): Unit = {
    // Cr√©ation de la session Spark
    val spark = SparkSession.builder()
      .appName("CCF Scala RDD")
      .master("local[*]") // Ex√©cution locale avec tous les c≈ìurs de la machine
      .getOrCreate()

    val sc = spark.sparkContext
    import spark.implicits._

    // Liste des graphes √† analyser (format CSV)
    val files = Seq(
      ("data/G1_1k.csv", "G1"),
      ("data/G2_5k.csv", "G2"),
      ("data/G3_8k.csv", "G3"),
      ("data/G4_10k.csv", "G4")
    )

    // On stockera ici les r√©sultats pour chaque graphe
    var results = Seq.empty[(String, Long, Long, Int, Double)]

    // Boucle sur chaque fichier
    files.foreach { case (path, label) =>
      println(s"\nüìé Analyse du graphe $label ($path)")

      // Lecture du fichier CSV brut
      val raw = sc.textFile(path)

      // On filtre l'en-t√™te et on extrait les ar√™tes sous forme de paires (source, target)
      val edges = raw
        .filter(!_.startsWith("source")) // Ignorer la premi√®re ligne
        .map(_.split(","))               // D√©coupage CSV
        .map(arr => (arr(0).toInt, arr(1).toInt)) // Conversion en entiers

      val nbEdges = edges.count() // Nombre total d‚Äôar√™tes
      val nbNodes = edges.flatMap(e => Seq(e._1, e._2)).distinct().count() // Sommets uniques

      // Lancement de l‚Äôalgorithme CCF version RDD
      val (components, iters, duration) = ccfRdd(edges)

      println(s"üîÅ Nombre d'it√©rations : $iters")
      println(f"‚è±Ô∏è Temps d'ex√©cution : $duration%.3f sec")
      println("-" * 40)

      // On ajoute les r√©sultats pour ce graphe
      results = results :+ (label, nbNodes, nbEdges, iters, duration)
    }

    // Affichage du r√©sum√© des performances
    val dfResults = results.toDF("Graphe", "Noeuds", "Ar√™tes", "It√©rations", "Temps (s)")
    println("\n‚úÖ R√©sum√© des performances :")
    dfResults.show(truncate = false)

    // Arr√™t de la session Spark
    spark.stop()
  }

  // Impl√©mentation de l'algorithme Connected Components (CCF) en RDD
  def ccfRdd(edges: RDD[(Int, Int)], maxIters: Int = 50): (RDD[(Int, Int)], Int, Double) = {
    // On commence par √©liminer les doublons (on veut que (2,3) et (3,2) soient trait√©s comme une seule ar√™te)
    val dedupedEdges = edges
      .map { case (a, b) =>
        if (a < b) (a, b) else (b, a) // On trie chaque paire pour pouvoir supprimer les doublons
      }
      .distinct()

    // Initialisation : chaque n≈ìud commence dans sa propre composante
    var components = dedupedEdges
      .flatMap(e => Seq(e._1, e._2))
      .distinct()
      .map(n => (n, n)) // (n≈ìud, composante)

    // Construction de la table des voisins pour chaque n≈ìud
    val neighbors = dedupedEdges
      .flatMap { case (a, b) => Seq((a, b), (b, a)) } // Graphe non-orient√©
      .groupByKey()
      .mapValues(_.toList)

    var converged = false
    var i = 0
    val startTime = System.nanoTime()

    // Boucle d'it√©rations de l‚Äôalgorithme
    while (!converged && i < maxIters) {
      // Pour chaque n≈ìud, on r√©cup√®re sa composante actuelle et on la propage √† ses voisins
      val joined = neighbors.join(components)

      val propagated = joined.flatMap { case (node, (neighs, comp)) =>
        (neighs :+ node).map(n => (n, comp)) // Chaque voisin (et le n≈ìud lui-m√™me) re√ßoit la composante
      }

      // Chaque n≈ìud garde la plus petite composante re√ßue
      val newComponents = propagated.reduceByKey(math.min)

      // On compte combien de n≈ìuds ont chang√© de composante par rapport √† l‚Äôit√©ration pr√©c√©dente
      val changes = components.join(newComponents)
        .filter { case (_, (oldC, newC)) => oldC != newC }
        .count()

      // Si aucun changement, on a converg√©
      converged = (changes == 0)
      components = newComponents
      i += 1
    }

    val durationSec = (System.nanoTime() - startTime) / 1e9

    // On retourne les composantes finales, le nombre d'it√©rations, et le temps d'ex√©cution
    (components, i, durationSec)
  }
}
